{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from functools import cache\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import permutations, combinations\n",
    "import plotly.express as px\n",
    "\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "from diff_functions import diff2_inline, diff_inline, diff_n, score_n_all, score_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2315 12953\n"
     ]
    }
   ],
   "source": [
    "# load words\n",
    "\n",
    "def load_words(filename):\n",
    "    with open(filename) as f:\n",
    "        return f.read().split()\n",
    "\n",
    "core = load_words('core.txt')\n",
    "extended = load_words('extended.txt')\n",
    "print(len(core), len(extended))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 56\n",
      "80 40\n"
     ]
    }
   ],
   "source": [
    "g, y = diff_inline(\"abcde\", \"abcde\")\n",
    "import sys\n",
    "\n",
    "print(sys.getsizeof(g), sys.getsizeof(y))\n",
    "print(sys.getsizeof(tuple(g)), sys.getsizeof(tuple(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats\n",
    "\n",
    "import math\n",
    "\n",
    "def most_common(corpus, n=15):\n",
    "    freq = Counter()\n",
    "    for word in corpus:\n",
    "        freq.update(word)\n",
    "    df = pd.DataFrame(list(zip(*freq.most_common(26)))).T\n",
    "    df.columns = ['Letter', 'Count']\n",
    "    df['Count'] = df['Count'].astype(\"int32\")\n",
    "    total = sum(df['Count'])\n",
    "    df['Frequency'] = df['Count'] / total\n",
    "    print(df)\n",
    "    fig = px.bar(df, x='Letter', y='Frequency', color='Frequency', color_continuous_scale=\"viridis\")\n",
    "    fig.update_coloraxes(showscale=False)\n",
    "    fig.show()\n",
    "    return [e[0] for e in freq.most_common(n)]\n",
    "\n",
    "print(most_common(core))\n",
    "# print(most_common(extended))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More stats \n",
    "\n",
    "def histogram(corpus):\n",
    "    counts = [[0,0,0,0,0] for i in range(26)]\n",
    "    offset = ord('A')\n",
    "    for word in corpus:\n",
    "        for idx, letter in enumerate(word):\n",
    "            counts[ord(letter) - offset][idx] += 1\n",
    "    return counts\n",
    "\n",
    "counts = histogram(core)\n",
    "\n",
    "counts_df = pd.DataFrame(counts)\n",
    "counts_df.columns = [str(i) for i in range(1, 6)]\n",
    "counts_df['Letter'] = [chr(i + ord('A')) for i in range(26)]\n",
    "sorted_last = counts_df.sort_values(by='5', ascending=False)\n",
    "sorted_last = sorted_last[['Letter', '5']]\n",
    "total = sum(sorted_last['5'])\n",
    "label = 'Frequency of last word letter'\n",
    "sorted_last[label] = sorted_last['5'] / total\n",
    "# print(sorted_last)\n",
    "last_freq = px.bar(sorted_last, x='Letter', y=label, color=label, color_continuous_scale=\"viridis\")\n",
    "last_freq.update_coloraxes(showscale=False)\n",
    "last_freq.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy\n",
    "\n",
    "def entropy(letter_counts):\n",
    "    total = sum(letter_counts)\n",
    "    probs = [ x / total for x in letter_counts ]\n",
    "    return -sum([ p * math.log(p, 2) for p in probs if p > 0])\n",
    "\n",
    "for i in range(5):\n",
    "    print(i, entropy([c[i] for c in counts]))\n",
    "\n",
    "global_freqs = [sum(c) for c in counts]\n",
    "print(entropy(global_freqs))\n",
    "total = sum(global_freqs)\n",
    "probs = [ x / total for x in global_freqs ]\n",
    "for i in range(26):\n",
    "    print(chr(i + ord('A')), -math.log(probs[i], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute match between two words\n",
    "WELL_PLACED_BONUS = 2\n",
    "\n",
    "def score(word1, word2):\n",
    "    well_placed = sum([1 if c1 == c2 else 0 for c1, c2 in zip(word1, word2)])\n",
    "    letters1 = Counter(word1)\n",
    "    letters2 = Counter(word2)\n",
    "    matches = 0\n",
    "    for letter, count in letters1.items():\n",
    "        matches += min(count, letters2.get(letter, 0))\n",
    "    return (well_placed, matches - well_placed)\n",
    "\n",
    "def score_inline(word1, word2):\n",
    "    wp, np = diff_inline(word1, word2)\n",
    "    wpcount = sum([1 if a else 0 for a in wp])\n",
    "    return (wpcount, len(np))\n",
    "\n",
    "assert score(\"aaaaa\", \"bbbbb\") == (0,0)\n",
    "assert score(\"abcde\", \"axxxx\") == (1,0)\n",
    "assert score(\"abcde\", \"abcde\") == (5,0)\n",
    "assert score(\"aabcd\", \"aabcd\") == (5,0)\n",
    "assert score(\"abcde\", \"bcdea\") == (0,5)\n",
    "assert score(\"aayyy\", \"axxxa\") == (1,1)\n",
    "assert score(\"axaxc\", \"xxaab\") == (2,2)\n",
    "\n",
    "assert score_inline(\"aaaaa\", \"bbbbb\") == (0,0)\n",
    "assert score_inline(\"abcde\", \"axxxx\") == (1,0)\n",
    "assert score_inline(\"abcde\", \"abcde\") == (5,0)\n",
    "assert score_inline(\"aabcd\", \"aabcd\") == (5,0)\n",
    "assert score_inline(\"abcde\", \"bcdea\") == (0,5)\n",
    "assert score_inline(\"aayyy\", \"axxxa\") == (1,1)\n",
    "assert score_inline(\"axaxc\", \"xxaab\") == (2,2)\n",
    "\n",
    "def diff(word1, word2):\n",
    "    well_placed = [c1 if c1 == c2 else None for c1, c2 in zip(word1, word2)]\n",
    "    well_placed_counter = Counter(well_placed)\n",
    "    letters1 = Counter(word1)\n",
    "    letters2 = Counter(word2)\n",
    "    not_placed = []\n",
    "    for letter, count in letters1.items():\n",
    "        matches = min(count, letters2.get(letter, 0)) - well_placed_counter.get(letter, 0)\n",
    "        not_placed.extend([letter]*matches)\n",
    "    return well_placed, not_placed\n",
    "\n",
    "assert diff(\"aaaaa\", \"bbbbb\") == ([None]*5,[])\n",
    "assert diff(\"abcde\", \"axxxx\") == (['a',None,None,None,None],[])\n",
    "assert diff(\"abcde\", \"abcde\") == (['a','b','c','d','e'],[])\n",
    "assert diff(\"aabcd\", \"aabcd\") == (['a','a','b','c','d'],[])\n",
    "assert diff(\"abcde\", \"bcdea\") == ([None]*5,['a','b','c','d','e'])\n",
    "assert diff(\"aayyy\", \"axxxa\") == (['a',None,None,None,None],['a'])\n",
    "assert diff(\"axaxc\", \"xxaab\") == ([None,'x','a',None,None],['a','x'])\n",
    "\n",
    "def delta(well_placed, not_placed, well_placed2):\n",
    "    for (a,b) in zip(well_placed, well_placed2):\n",
    "        #if letter is well placed in first word AND not well placed in second word\n",
    "        if a and not b and a in not_placed:\n",
    "            not_placed.remove(a)\n",
    "    return not_placed\n",
    "\n",
    "def merge(list1, list2):\n",
    "    result = []\n",
    "    for a in list1:\n",
    "        if a in list2:\n",
    "            list2.remove(a)\n",
    "        result.append(a)\n",
    "    result.extend(list2)\n",
    "    return result\n",
    "\n",
    "def diff2(base, word1, word2):\n",
    "    well_placed1, not_placed1 = diff(base, word1)\n",
    "    well_placed2, not_placed2 = diff(base, word2)\n",
    "    well_placed = [a or b for (a,b) in zip(well_placed1, well_placed2)]\n",
    "    not_placed = merge(delta(well_placed1, not_placed2, well_placed2), delta(well_placed2, not_placed1, well_placed1))\n",
    "    return well_placed, not_placed\n",
    "\n",
    "def compare(diff_result, str1, str2):\n",
    "    wp, np = diff_result\n",
    "    wp2 = [None if c == '*' else c for c in str1]\n",
    "    np2 = list(str2)\n",
    "    assert wp == wp2\n",
    "    assert(sorted(np) == sorted(np2))\n",
    "\n",
    "def score2_generic(diff2_func, base, w1, w2):\n",
    "    wp, np = diff2_func(base, w1, w2)\n",
    "    wpcount = sum([1 if a else 0 for a in wp])\n",
    "    return wpcount*WELL_PLACED_BONUS + len(np)\n",
    "\n",
    "\n",
    "compare(diff2(\"aaaaa\", \"bbbbb\", \"ccccc\"), '*****', '')\n",
    "compare(diff2(\"aaaaa\", \"abbbb\", \"aaccc\"), 'aa***', '')\n",
    "compare(diff2(\"aaxxx\", \"abbbb\", \"acxca\"), 'a*x**', 'a')\n",
    "compare(diff2(\"aaxxx\", \"bbbaa\", \"cxxca\"), '**x**', 'aax')\n",
    "compare(diff2(\"toxic\",\"train\",\"taper\"), 't**i*', '')\n",
    "compare(diff2(\"rapid\",\"train\",\"taper\"), '*api*','r')\n",
    "compare(diff2(\"affix\",\"taper\",\"bring\"), '*****','ai')\n",
    "compare(diff2(\"tapir\",\"train\",\"taper\"), 'tapir', '')\n",
    "compare(diff2(\"tapir\",\"train\",\"paste\"), 'ta*i*', 'rp')\n",
    "\n",
    "assert diff(\"aaaaa\", \"bbbbb\") == diff2(\"aaaaa\", \"bbbbb\", \"bbbbb\")\n",
    "assert diff(\"abcde\", \"axxxx\") == diff2(\"abcde\", \"axxxx\", \"axxxx\")\n",
    "assert diff(\"abcde\", \"abcde\") == diff2(\"abcde\", \"abcde\", \"abcde\")\n",
    "assert diff(\"aabcd\", \"aabcd\") == diff2(\"aabcd\", \"aabcd\", \"aabcd\")\n",
    "assert diff(\"abcde\", \"bcdea\") == diff2(\"abcde\", \"bcdea\", \"bcdea\")\n",
    "assert diff(\"aayyy\", \"axxxa\") == diff2(\"aayyy\", \"axxxa\", \"axxxa\")\n",
    "assert diff(\"axaxc\", \"xxaab\") == diff2(\"axaxc\", \"xxaab\", \"xxaab\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def average(l):\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "def score_all(word, corpus):\n",
    "    def score_one(w1, w2):\n",
    "        a, b = score_inline(w1, w2)\n",
    "        return a*WELL_PLACED_BONUS + b\n",
    "    return average([score_one(word, w) for w in corpus])\n",
    "\n",
    "def score2_all(diff_func, w1, w2, corpus):\n",
    "    return average([score2_generic(diff_func, w, w1, w2) for w in corpus])\n",
    "\n",
    "def score_n_all(words, corpus):\n",
    "    def score_n_1(base, words):\n",
    "        greens, yellows = diff_n(base, words)\n",
    "        green_count = sum([1 if a else 0 for a in greens])\n",
    "        return green_count*WELL_PLACED_BONUS + len(yellows)\n",
    "    return average([score_n_1(w, words) for w in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_n_all(['SOARE', 'CLINT', 'PUDGY'], core))\n",
    "print(score_n_all(['TRAIN', 'LOUSE', 'CHIMP'], core))\n",
    "print(score_n_all(['SLATE', 'IRONY', 'CHUMP'], core))\n",
    "print(score_n_all(['STAIR', 'CLONE', 'PUDGY'], core))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and cache scores\n",
    "\n",
    "cached_scores = {}\n",
    "first_two = \"\"\n",
    "for w in extended:\n",
    "    cached_scores[w] = score_all(w, core)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first attempt to find a starting pair of words\n",
    "\n",
    "def find_pairs(corpus):\n",
    "    result = []\n",
    "    target_list = most_common(core, 10)\n",
    "    target_set = set(target_list)\n",
    "    corpus_set = set(corpus)\n",
    "    first_two = \"\"\n",
    "    tested = 0\n",
    "    for word in corpus:\n",
    "        if False and word[:2] != first_two:\n",
    "            first_two = word[:2]\n",
    "            print(f\"{first_two} {tested} {len(result)}\")\n",
    "            tested = 0\n",
    "        letter_set = set(word)\n",
    "        if len(letter_set) != 5:\n",
    "            continue\n",
    "        if not letter_set.issubset(target_set):\n",
    "            continue\n",
    "        tested += 1\n",
    "        remaining = target_set - letter_set\n",
    "        for perm in permutations(remaining):\n",
    "            candidate = ''.join(perm)\n",
    "            if candidate in corpus_set:\n",
    "                score1 = cached_scores[word]\n",
    "                score2 = cached_scores[candidate]\n",
    "                result.append((score1 + score2, score1, word, candidate))\n",
    "        \n",
    "    return sorted(result)\n",
    "\n",
    "\n",
    "result_core = find_pairs(core)\n",
    "result_core.reverse()\n",
    "result_extended = find_pairs(extended)\n",
    "result_extended.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "\n",
    "def format(word):\n",
    "    if word in core:\n",
    "        return f\"**{word}**\"\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "for result in (result_core, result_extended):\n",
    "    print(len(result))\n",
    "    print('\\n'.join([f\"{format(r[2])}, {format(r[3])} ({r[0]:.3f})\" for r in result[0:20:2]]))\n",
    "\n",
    "    scores = pd.DataFrame(result, columns=['score', 'score1', 'word1', 'word2'])\n",
    "    scores.hist(column='score', bins=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats on word scores\n",
    "\n",
    "word_scores = pd.DataFrame(cached_scores.items())\n",
    "word_scores.columns = [\"word\", \"score\"]\n",
    "core_set = set(core)\n",
    "word_scores[\"core\"] = word_scores.apply(lambda r: r[\"word\"] in core_set, axis=1)\n",
    "word_scores[\"sort_key\"] = word_scores.apply(lambda r: (r[\"score\"],r[\"word\"]), axis=1)\n",
    "print(word_scores)\n",
    "word_scores.hist(column=\"score\", bins=50)\n",
    "m = word_scores['score'].median()\n",
    "print(word_scores.min())\n",
    "print(word_scores.max())\n",
    "print(word_scores.mean())\n",
    "med = [w for (w,s) in cached_scores.items() if abs(s - m) < 10**-8]\n",
    "print([(x, cached_scores[x]) for x in med])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_scores[word_scores.core == True].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a 3rd word for the first method\n",
    "\n",
    "third_word_candidates = most_common(core, 26)[10:]\n",
    "print(third_word_candidates)\n",
    "\n",
    "third_words = []\n",
    "for perm in permutations(third_word_candidates, 5):\n",
    "    candidate = ''.join(perm)\n",
    "    if candidate in cached_scores:\n",
    "        # third_words.append([candidate, cached_scores[candidate], candidate in core])\n",
    "        third_words.append((candidate, cached_scores[candidate], candidate in core))\n",
    "third_words.sort(key=lambda r: r[1], reverse=True)\n",
    "\n",
    "def format(w,c):\n",
    "    if c:\n",
    "        return f\"**{w}**\"\n",
    "    else:\n",
    "        return w\n",
    "for (w, s, c) in third_words:\n",
    "    print(f\"|{format(w, c)} | {s:.3f} |\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1818574514038875"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_scores[\"SOARE\"] + cached_scores[\"CLINT\"] # + cached_scores[\"PUDGY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Second attempt to find starting pair\n",
    "\n",
    "extended_by_score = [x[0] for x in sorted(cached_scores.items(), key=lambda x: x[1], reverse=True)]\n",
    "core_set = set(core)\n",
    "core_by_score = [x for x in extended_by_score if x in core_set]\n",
    "\n",
    "def find_best_pairs(corpus, threshold=4):\n",
    "    best = 0\n",
    "    h= []\n",
    "    tested, skipped = 0, 0\n",
    "    next_thresh = 1000\n",
    "    n = len(corpus)\n",
    "    for i in range(n):\n",
    "        w1 = corpus[i]\n",
    "        score1 = cached_scores[w1]\n",
    "        if score1*2 < threshold:\n",
    "            print(f'Stopping at index {i} ({w1}); score = {score1}')\n",
    "            break\n",
    "        for j in range(i+1, n):\n",
    "            w2 = corpus[j]\n",
    "            score2 = cached_scores[w2]\n",
    "            if score1 + score2 < threshold:\n",
    "                skipped += n - j\n",
    "                break\n",
    "            if tested + skipped >= next_thresh:\n",
    "                print(f'(tested {tested}, skipped {skipped})')\n",
    "                next_thresh = ((tested + skipped) / 1000 + 1) * 1000\n",
    "            tested += 1\n",
    "            score = score2_all(diff2_inline, w1, w2, core)\n",
    "            h.append((score, w1, w2))\n",
    "            if score > best:\n",
    "                print(f'New best: {w1} {w2} {score} (tested {tested}, skipped {skipped})')\n",
    "                best = score\n",
    "        \n",
    "    print(f\"Tested: {tested}, skipped: {skipped}, total {skipped + tested}\")\n",
    "    return sorted(h, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = find_best_pairs(core_by_score)\n",
    "\n",
    "# Took 6m24s with cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = find_best_pairs(extended_by_score)\n",
    "\n",
    "# Took 198m 44s without cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a  way to compute the score for a pair from indicidual scores ?\n",
    "\n",
    "def score_diff(word1, word2):\n",
    "    wp, np = score(word1, word2)\n",
    "    return wp*WELL_PLACED_BONUS + np\n",
    "\n",
    "    \n",
    "correlation_analysis = pd.DataFrame(r1, columns=['score', 'word1', 'word2'])\n",
    "correlation_analysis['score1'] = correlation_analysis.apply(lambda r: cached_scores[r['word1']], axis=1)\n",
    "correlation_analysis['score2'] = correlation_analysis.apply(lambda r: cached_scores[r['word2']], axis=1)\n",
    "correlation_analysis['total'] = correlation_analysis.apply(lambda r: r['score1'] + r['score2'], axis=1)\n",
    "correlation_analysis['delta'] = correlation_analysis.apply(lambda r: r['total'] - r['score'], axis=1)\n",
    "correlation_analysis['diff'] = correlation_analysis.apply(lambda r: score_diff(r['word1'], r['word2']), axis=1)\n",
    "print(correlation_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = px.scatter(correlation_analysis, x=\"delta\", y=\"diff\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_pairs = json.load(open('extended_pairs.json'))\n",
    "core_pairs = json.load(open('core_pairs.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results for second method\n",
    "\n",
    "def format(word):\n",
    "    if word in core:\n",
    "        return f\"**{word}**\"\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "for result in (core_pairs, extended_pairs):\n",
    "    print(len(result))\n",
    "    print('\\n'.join([f\"| {format(r[1])} | {format(r[2])} | {r[0]:.3f}|\" for r in result[0:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 3rd word for second method (Note: outdated, see truplets.py)\n",
    "\n",
    "def search(pairs, corpus, threshold=5):\n",
    "    best = 0\n",
    "    results = []\n",
    "    for p in pairs:\n",
    "        print(f\"***** {p[1]} {p[2]} *****\")\n",
    "        pair_score = p[0]\n",
    "        for third in corpus:\n",
    "            third_score = cached_scores[third]\n",
    "            if pair_score + third_score < threshold:\n",
    "                break\n",
    "            triplet = (p[1], p[2], third)\n",
    "            score = score_n_all(triplet, core)\n",
    "            results.append((score, *triplet))\n",
    "            if score > best:\n",
    "                print(f'New best: {triplet} {score}')\n",
    "                best = score\n",
    "    return sorted(results, reverse=True)\n",
    "\n",
    "r1 = search(core_pairs[:100], core_by_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the triplets files are generated by triplets.py\n",
    "\n",
    "extended_triplets = json.load(open('extended_triplets.json'))\n",
    "core_triplets = json.load(open('core_triplets.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(triplet, pairs):\n",
    "    for i, p in enumerate(pairs):\n",
    "        if p[1] == triplet[1] and p[2] == triplet[2]:\n",
    "            return i\n",
    "\n",
    "for r in extended_triplets[:10]:\n",
    "    i = lookup(r, extended_pairs)\n",
    "    print(f\"| {format(r[1])} | {format(r[2])} | {format(r[3])} | {r[0]:.3f}| {i}| \")\n",
    "\n",
    "for r in core_triplets[:20]:\n",
    "    i = lookup(r, core_pairs)\n",
    "    print(f\"| {r[1]} | {r[2]} | {r[3]} | {r[0]:.3f}| {i}| \")\n",
    "\n",
    "#print(extended_triplets[:20])\n",
    "#print(\"*****\")\n",
    "# print(core_triplets[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 [5.365442764578834, 'CRATE', 'SOILY', 'BUNDH']\n",
      "51 [5.230669546436285, 'SLATE', 'IRONY', 'CHUMP']\n",
      "1.092 1.941 0.924 2.127\n",
      "5.390928725701944 -5.943844492440604 4.838012958963283\n",
      "5.888552915766738 -1.9075593952483842 9.869546436285091\n"
     ]
    }
   ],
   "source": [
    "# print out the scores for some triplets\n",
    "\n",
    "p_e = extended_pairs[0][1:]\n",
    "c_e = core_pairs[0][1:]\n",
    "\n",
    "for i, t in enumerate(extended_triplets):\n",
    "    if t[1] == p_e[0] and t[2] == p_e[1]:\n",
    "        print(i, t)\n",
    "        break\n",
    "\n",
    "for i, t in enumerate(core_triplets):\n",
    "    if t[1] == c_e[0] and t[2] == c_e[1]:\n",
    "        print(i, t)\n",
    "        break\n",
    "\n",
    "# print(score_n_all([\"TRAIN\", \"LOUSE\", \"CHIMP\"], core))\n",
    "def score_n_with_details(words, corpus):\n",
    "    def score_n_1(base, words):\n",
    "        greens, yellows = diff_n(base, words)\n",
    "        green_count = sum([1 if a else 0 for a in greens])\n",
    "        return (green_count, len(yellows))\n",
    "    greens, yellows = 0, 0\n",
    "    for w in corpus:\n",
    "        g, y = score_n_1(w, words)\n",
    "        greens += g\n",
    "        yellows += y\n",
    "    return (greens/len(corpus), yellows/len(corpus))\n",
    "\n",
    "g1, y1 = score_n_with_details([\"SLATE\", \"IRONY\"], core)\n",
    "g2, y2 = score_n_with_details([\"TRAIN\", \"LOUSE\"], core)\n",
    "print(f\"{g1:.3f} {y1:.3f} {g2:.3f} {y2:.3f}\")\n",
    "print(32*(g1 - g2), 32*(y1 - y2), 32*(g1 - g2)*2 + 32*(y1 - y2))\n",
    "g3, y3 = score_n_with_details([\"SLATE\"], core)\n",
    "g4, y4 = score_n_with_details([\"TRAIN\"], core)\n",
    "print(32*(g3 - g4), 32*(y3 - y4), 32*(g3 - g4)*2 + 32*(y3 - y4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34999 0.84461 1.54459\n"
     ]
    }
   ],
   "source": [
    "# check that on average, 2 words have a score of ~1.5\n",
    "\n",
    "import random\n",
    "\n",
    "def score_one(w1, w2):\n",
    "    greens, yellows = diff_inline(w1, w2)\n",
    "    a = sum([1 if a else 0 for a in greens])\n",
    "    return a*2 + len(yellows)\n",
    "\n",
    "n = 10**5\n",
    "tot_g, tot_y = 0, 0\n",
    "for _ in range(n):\n",
    "    w1 = random.choice(core)\n",
    "    w2 = random.choice(extended)\n",
    "    g, y = diff_inline(w1, w2)\n",
    "    tot_g += sum([1 if a else 0 for a in g])\n",
    "    tot_y += len(y)\n",
    "print(tot_g/n, tot_y/n, (tot_g*2 + tot_y)/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for triplets with the same score\n",
    "scores = defaultdict(set)\n",
    "for s in (extended_triplets, core_triplets):\n",
    "    for score, *triplet in s:\n",
    "        scores[score].add(tuple(sorted(triplet)))\n",
    "\n",
    "sets = []\n",
    "for triplets in scores.values():\n",
    "    if len(triplets) > 1:\n",
    "        sets.append(len(triplets))\n",
    "print(sorted(sets, reverse=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('wordle-FV252oEg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c5ecce12c35319fe7e714c2440e8dfe8cc2fc27ef6af97cececcb16b17f856f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
